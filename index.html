<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->

  <meta name="description" content="
      We utilize natural language to articulate robotics policy, 
      focusing on advanced and unprecedented efficient embodied control, 
      rather than relying on code.">

  <meta property="og:title"
    content="Natural Language as Policies(NLaP): Reasoning for Coordinate-Level Embodied Control with LLMs" />

  <meta property="og:description" content="
            Our approach offers robotics planning in natural language context with LLMs." />

  <meta property="og:url" content="https://shure-dev.github.io/" />

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/overview.jpg" />

  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title"
    content="Natural Language as Policies: Reasoning for Coordinate-Level Embodied Control with LLMs">
  <meta name="twitter:description" content="
        We utilize natural language to articulate robotics policy, 
        focusing on advanced and unprecedented efficient embodied control, 
        rather than relying on code.">

  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/overview.jpg">
  <meta name="twitter:card" content="static/images/overview.jpg">
  <!-- Keywords for your paper to be indexed by-->

  <meta name="keywords" content="NLaP: Natural Language as Policies: Reasoning for Coordinate-Level 
            Embodied Control with LLMs
            Arxiv, Yusuke Mikami, Robot, LLM, ChatGPT, OpenAI, Reasoning, 
            Chain of Thought, IROS, 2024, Policy, Agent, Reinforcement Learning, 
            Robotics, Embodied, Large Language Model
            In-Context Learning, NLP, AGI, AI, Github, Code as Policies, 
            CaP, Progprompt, Text2Motion, Zero-shot, Instruct2Act, EmbodiedGPT, 
            RoboGPT, Inner Monologue, Socratic Models, Statler, Demo2Code, 
            GPT-4V(ision) for Robotics, Tree-Planner, Survey, Prompt, VLM,
            CoT / VLM / Quantization / Grounding / Text2IMG&VID / Prompt / Reasoning / Robot 
            / Agent / Planning / RL / Feedback / InContextLearning / InstructionTuning / 
            PEFT / RLHF / RAG / Embodied / VQA / Hallucination / Diffusion / Scaling / ContextWindow / 
            WorldModel / Memory / ZeroShot / RoPE / Speech, NLaP">

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Natural Language as Policies(NLaP): Reasoning for Coordinate-Level Embodied Control with LLMs</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">

            <h1 class="title is-1 publication-title">
              Natural Language as Policies:
              <!-- Reasoning for Coordinate-Level
              Embodied Control with LLMs -->
            </h1>

            <h2 class="title is-2 publication-title">
              Reasoning for Coordinate-Level
              Embodied Control with LLMs
            </h2>

<!-- 
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://github.com/shure-dev" target="_blank">
                  Yusuke Mikami</a>
                , Andrew Melnik, Jun Miura, Ville Hautamäki
                <sup></span>
            </div> -->

            <!-- <div class="is-size-5 publication-authors">
              <span class="author-block">
                Preprint. Under review.
              </span>
            </div> -->

            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://sites.google.com/view/yusukemikami/home" target="_blank">Yusuke Mikami</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.co.jp/citations?user=6tiiQtgAAAAJ&hl=ja&oi=sra" target="_blank">Andrew Melnik</a><sup>3</sup>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=vLWDx4YAAAAJ&hl=en" target="_blank">Jun Miura</a><sup>1</sup>,</span>
                    
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?user=esQWyTcAAAAJ&hl=ja" target="_blank">Ville Hautamäki</a><sup>2</sup>
                  </span>

                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Preprint. Under review.</span>
                    <span class="eql-cntrb"><small><br>
                      <sup>1</sup>Department of Computer Science and Engineering at Toyohashi University of Technology, Japan.
                      <sup>2</sup>School of Computing at University of Eastern Finland, Finland.
                      <sup>3</sup>Bielefeld University, Germany.</span>
                    </small>

                  </div>
            <!-- 
            <span class="link-block">
              <a href="https://github.com/shure-dev/NLaP" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>GitHub</span>
              </a>
            </span> -->

            <div class="column has-text-centered">
              <div class="publication-links">
                   <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2403.13801.pdf" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <!-- Supplementary PDF link -->
              <!-- <span class="link-block">
                <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>ArXiv HTML</span>
              </a>
            </span> -->

            <!-- Github link -->
            <!-- <span class="link-block">
              <a href="https://github.com/YOUR REPO HERE" target="_blank"
              class="external-link button is-normal is-rounded is-dark">
              <span class="icon">
                <i class="fab fa-github"></i>
              </span>
              <span>Code</span>
            </a>
          </span> -->

          <!-- ArXiv abstract Link -->
          <span class="link-block">
            <a href="https://arxiv.org/abs/2403.13801" target="_blank"
            class="external-link button is-normal is-rounded is-dark">
            <span class="icon">
              <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
        </span>



            <div>

              <!-- <br>

              <a href="https://arxiv.org/abs/2403.13801"><img alt="Static Badge"
                  src="https://img.shields.io/badge/arXiv-2403.13801-b31b1b.svg?style=flat"></a>

              <a href="https://arxiv.org/html/2403.13801v1"><img alt="Static Badge"
                  src="https://img.shields.io/badge/arXiv-HTML-red"></a>

              <a href="https://paperswithcode.com/paper/natural-language-as-policies-reasoning-for">
                <img alt="Static Badge" src="https://img.shields.io/badge/PaperWithCode-blue">
              </a>

              <a href="https://github.com/shure-dev/NLaP">
                <img alt="Static Badge" src="https://img.shields.io/badge/GitHub-NLaP-black"></a>

              <br>
              <br> -->
              <br>
              <br>
              <!-- <iframe width="110%" height="800vh" scrolling="no"
                src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D893%253A60%26type%3Ddesign%26node-id%3D893-344%26viewport%3D670%252C1339%252C0.4%26t%3DehrkE3WEd7UmW471-1%26scaling%3Dmin-zoom%26starting-point-node-id%3D893%253A335%26mode%3Ddesign"
                allowfullscreen></iframe> -->

                <iframe width="110%" height="850vh" 
                src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D893%253A60%26type%3Ddesign%26node-id%3D893-335%26viewport%3D3923%252C1398%252C0.43%26t%3D4jYBQaYjHJ2NTu7C-1%26scaling%3Dscale-down%26starting-point-node-id%3D893%253A335%26mode%3Ddesign"
                allowfullscreen scrolling="no"></iframe>
                
            <style>
                iframe {
                    pointer-events: none;
                }
            </style>




                <!-- <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="800" height="450" src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D893%253A60%26type%3Ddesign%26node-id%3D893-344%26viewport%3D670%252C1339%252C0.4%26t%3DehrkE3WEd7UmW471-1%26scaling%3Dmin-zoom%26starting-point-node-id%3D893%253A335%26mode%3Ddesign" allowfullscreen></iframe> -->


              <!-- <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="800" height="450" src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D0%253A1%26type%3Ddesign%26node-id%3D1-2%26viewport%3D28%252C382%252C0.07%26t%3DPP8XpRODO5qgZQRQ-1%26scaling%3Dcontain%26mode%3Ddesign" allowfullscreen></iframe>
              <iframe style="border: 1px solid rgba(0, 0, 0, 0.1);" width="800" height="450" src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D0%253A1%26type%3Ddesign%26node-id%3D8-7%26viewport%3D28%252C382%252C0.07%26t%3DPP8XpRODO5qgZQRQ-1%26scaling%3Dscale-down%26mode%3Ddesign" allowfullscreen></iframe> -->
              <!-- <iframe style="border: 1px solid rgb(255, 255, 255);" 
              width="900" height="700" 
              src="https://www.figma.com/embed?embed_host=share&url=https%3A%2F%2Fwww.figma.com%2Fproto%2F9zQ6JLfagDG03OA3g53n5s%2FNLaP%3Fpage-id%3D0%253A1%26type%3Ddesign%26node-id%3D8-77%26viewport%3D121%252C330%252C0.29%26t%3D5fds8TNDnkGyWK2m-1%26scaling%3Dcontain%26mode%3Ddesign" allowfullscreen></iframe> -->


              <!-- <br>
              <br>

              <div>
                <img src="static/images/overview.png" 
                  alt="drawddding" width="600"/>
              </div> -->

              <!-- <div>
                <img src="static/images/Mapping.png"
                  alt="drawing" width="700" />
              </div> -->

            </div>



            <!-- <span class="link-block">
                  <a href="https://potent-twister-29f.notion.site/b0fc32542854456cbde923e0adb48845?v=ee8b1facc0cf4bfebd88c36a515430a5&pvs=4" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Notion Table</span>

                </a>

              </span> -->
            <!-- ArXiv abstract Link -->
            <!--                 <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
          </div>
        </div>
      </div>
    </div>
    </div>
    </div>
  </section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <!-- Your image here -->
          <div class="center-image">
            <img src="static/images/examples/vizual_manipulation.png" alt="MY ALT TEXT" width="600"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Visual manipulation
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <div class="center-image">
            <img src="static/images/examples/scene.png" alt="MY ALT TEXT" width="600"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Scene understanding
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <div class="center-image">
            <img src="static/images/examples/old.png" alt="MY ALT TEXT" width="600"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Old neighbor
          </h2>
        </div>
        <div class="item">
          <!-- Your image here -->
          <div class="center-image">
            <img src="static/images/examples/Sweep.png" alt="MY ALT TEXT" width="600"/>
          </div>
          <h2 class="subtitle has-text-centered">
            Sweep without exceeding
          </h2>
        </div>
      </div>
    </div>
  </div>
</section>

<style>
  .center-image {
    display: flex;
    justify-content: center;
  }
</style>

<script>
  // 自動スクロールの間隔（ミリ秒）
  var interval = 3000;

  // カルーセルの要素を取得
  var carousel = document.getElementById('results-carousel');

  // カルーセルのアイテムを取得
  var items = carousel.getElementsByClassName('item');

  // 現在のアイテムのインデックス
  var currentIndex = 0;

  // スクロール関数
  function scrollCarousel() {
    // 現在のアイテムを非表示にする
    items[currentIndex].classList.remove('active');
    // 次のアイテムのインデックスを更新
    currentIndex = (currentIndex + 1) % items.length;
    // 次のアイテムを表示する
    items[currentIndex].classList.add('active');
  }

  // カルーセルを自動スクロールさせるタイマーを設定
  setInterval(scrollCarousel, interval);
</script>






  <br>
  <br>

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstruct</h2>
          <div class="content has-text-justified">
            <p>

              We demonstrate experimental results with LLMs that address
              robotics action planning problems. Recently, LLMs have been
              applied in robotics action planning, particularly using a
              code generation approach that converts complex high-level
              instructions into mid-level policy codes. In contrast, our
              approach acquires text descriptions of the task and scene
              objects, then formulates action planning through natural
              language reasoning, and outputs coordinate level control
              commands, thus reducing the necessity for intermediate
              representation code as policies. Our approach is evaluated on a multi-modal prompt simulation benchmark,
              demonstrating that our prompt engineering experiments with natural language reasoning significantly
              enhance success rates compared to its absence. Furthermore, our approach illustrates the potential for
              natural language descriptions to transfer robotics skills from known tasks to previously unseen tasks.


            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <br>
  <br>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Intoroduction</h2>
          <div class="content has-text-justified">
            <p>

              In the recent LLM-based code generation approaches, we suppose there are three primal limitations. 
              First, code implementation itself lacks high-level contextual meaning to efficiently describe embodied skills since usually it is symbolized, indirectly connected to the scene, and abstracted in the in-context learning process. 
              Second, these approaches are limited by task-specific pre-defined APIs, such as CLIP. Utilizing high-level APIs in a perception module implies a limitation in flexibility, as it suggests an inability to perform tasks beyond that scope.
              Third, LLM output actions are policy codes with high-level pre-defined APIs, that is task-level, and prevent flexible planning in various environments.
              We hypothesize that the natural language description of the whole planning process, instead of code, can contribute to removing the limitations.
              
            </div>

              <div>
                <img src="static/images/problems.png" alt="drawing" width="600" />
              </div>

            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <br>
  <br>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Overview of our approach</h2>
          <div class="content has-text-justified">
            <p>

              We provide one demonstration as an in-context example, and a planning step employing natural language reasoning instead of conventional code implementation. 
              We remove the CoT reasoning component in the in-context example for our ablation study to check the importance of natural language reasoning. 
              We use low-level API(pick-and-place or sweep) to control the robot arm. We present specific examples of natural language reasoning in Table.
            </p>

          </div>
          <div>
            <img src="static/images/overview.png" 
              alt="drawddding" width="600"/>
          </div>
        </div>
        


      </div>
    </div>
  </section>


  <br>
  <br>


  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Specific Reasoning Examples</h2>
          <div class="content has-text-justified">


            Specific example of natural language reasoning we manually made for in-context learning. We do not have any
            specific format to produce these reasonings and we try to make natural reasoning in a human way.
            Target tasks are explained in https://vimalabs.github.io/

            <div>
              <img src="static/images/reasoning.png" alt="drawing" width="900" />
            </div>

          </div>
        </div>
      </div>
    </div>
  </section>

  <br>
  <br>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Difference from existing approaches</h2>
          <div class="content has-text-justified">
            <p>
              <p>
              Our appraoch does not output policy code, 
              does not use pre-defined APIs for perception, 
              and use only natural lanugage reasoning.
              </p>
            </div>

              <div>
                <img src="static/images/related_works.png" alt="drawing" width="500" />
              </div>

            </p>

          </div>
        </div>
      </div>
    </div>
  </section>

  <br>
  <br>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{mikami2024natural,
        title={Natural Language as Policies: Reasoning for Coordinate-Level Embodied Control with LLMs}, 
        author={Yusuke Mikami and Andrew Melnik and Jun Miura and Ville Hautamäki},
        year={2024},
        eprint={2403.13801},
        archivePrefix={arXiv},
        primaryClass={cs.RO}
  }</code></pre>
    </div>
  </section>


  <!-- <embed src="/static/pdfs/reasoning.pdf" width="800px" height="2100px" /> -->

  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
  
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
  
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>



</html>